apiVersion: karpenter.k8s.aws/v1alpha1
kind: AWSNodeTemplate
metadata:
  name: default
  labels:
    karpenter.sh/provisioner-name: default-provisioner
spec:
  instanceProfile: {{ .Values.aws.instanceProfile }}
  blockDeviceMappings:
    - deviceName: /dev/xvda
      ebs:
        volumeSize: 10Gi
        volumeType: gp3
        iops: 3000
        encrypted: true
        deleteOnTermination: true
        throughput: 750
  amiSelector:
    cpco.io/ami/type: k8s-worker
  subnetSelector:
    Name: "{{ .Values.clusterName }}-private*"
  securityGroupSelector:
    karpenter.sh/discovery/{{ .Values.clusterName }}: {{ .Values.clusterName }}
  tags:
    karpenter.sh/discovery/{{ .Values.clusterName }}: {{ .Values.clusterName }}
    Name: "{{ .Values.clusterName }}-k8s-worker"
    Provisioner: karpenter
  metadataOptions:
    httpEndpoint: enabled
  userData: |
    #!/bin/bash
    mkdir -p /home/ec2-user/.ssh/
    touch /home/ec2-user/.ssh/authorized_keys
    echo "{{ .Values.aws.sshPublicKey }}" | base64 -d >> /home/ec2-user/.ssh/authorized_keys
    chmod -R go-w ~ec2-user/.ssh/authorized_keys
    chown -R ec2-user ~ec2-user/.ssh
    echo "{{ .Values.apiAddress }}   {{ .Values.controlPlaneEndpoint }}" >> /etc/hosts
    AVAILABILITY_ZONE=$(wget -q -O - http://169.254.169.254/latest/meta-data/placement/availability-zone)
    INSTANCE_ID=$(wget -q -O - http://169.254.169.254/latest/meta-data/instance-id)
    LIFE_CYCLE=$(wget -q -O - http://169.254.169.254/latest/meta-data/instance-life-cycle)
    PROVIDER_ID="aws://$AVAILABILITY_ZONE/$INSTANCE_ID"
    NODE_NAME=$(hostname)

    sudo cat <<EOF | sudo tee cluster-join.yaml
    apiVersion: kubeadm.k8s.io/v1beta3
    kind: JoinConfiguration
    discovery:
      bootstrapToken:
        token: {{ .Values.joinToken }}
        apiServerEndpoint: {{ .Values.apiAddress }}:{{ .Values.apiPort }}
        caCertHashes:
          - {{ .Values.caCertHash }}
    nodeRegistration:
      name: "$NODE_NAME"
      kubeletExtraArgs:
        node-labels: "role=worker,karpenter.sh/initialized=true,karpenter.sh/registered=true,karpenter.sh/provisioner-name=default-provisioner,karpenter.sh/capacity-type=$LIFE_CYCLE"
        provider-id: "$PROVIDER_ID"
      taints:
        - effect: NoExecute
          key: node.cilium.io/agent-not-ready
    EOF

    sudo kubeadm join \
      --config cluster-join.yaml
