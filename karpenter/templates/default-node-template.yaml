apiVersion: karpenter.k8s.aws/v1alpha1
kind: AWSNodeTemplate
metadata:
  name: default
  labels:
    karpenter.sh/provisioner-name: default-provisioner
spec:
  instanceProfile: {{ .Values.aws.instanceProfile }}
  blockDeviceMappings:
    - deviceName: /dev/xvda
      ebs:
        volumeSize: 10Gi
        volumeType: gp3
        iops: 3000
        encrypted: true
        deleteOnTermination: true
        throughput: 750
  amiSelector:
    cpco.io/ami/type: k8s-worker
  subnetSelector:
    Name: "{{ .Values.clusterName }}-private*"
  securityGroupSelector:
    karpenter.sh/discovery/{{ .Values.clusterName }}: {{ .Values.clusterName }}
  tags:
    karpenter.sh/discovery/{{ .Values.clusterName }}: {{ .Values.clusterName }}
    Name: "{{ .Values.clusterName }}-k8s-worker"
    Provisioner: karpenter
  metadataOptions:
    httpEndpoint: enabled
  userData: |
    #!/bin/bash
    mkdir -p /home/ec2-user/.ssh/
    touch /home/ec2-user/.ssh/authorized_keys
    echo {{ .Values.aws.sshPublicKey }} >> /home/ec2-user/.ssh/authorized_keys
    chmod -R go-w ~ec2-user/.ssh/authorized_keys
    chown -R ec2-user ~ec2-user/.ssh

    NODE_NAME=$(hostname)
    sudo cat <<EOF | sudo tee cluster-join.yaml
    apiVersion: kubeadm.k8s.io/v1beta3
    kind: JoinConfiguration
    discovery:
      bootstrapToken:
        token: {{ .Values.joinToken }}
        apiServerEndpoint: {{ .Values.apiAddress }}:{{ .Values.apiPort }}"
        caCertHashes:
          - {{ .Values.caCertHash }}
    nodeRegistration:
      name: "$NODE_NAME"
      kubeletExtraArgs:
        node-labels: "role=worker"
    EOF

    sudo kubeadm join \
      --config cluster-join.yaml
